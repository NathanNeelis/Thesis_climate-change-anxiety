{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1029877",
   "metadata": {},
   "source": [
    "## Pre-processing steps:\n",
    "GET A BEFORE AND AFTER NUMBER.\n",
    "\n",
    "1. Delete rows that do not have an (unique) ID.   \n",
    "\t1.1 delete duplicate  \n",
    "\t1.2 delete rows with no ID  \n",
    "  \n",
    "2. Delete rows that do not have body text  \n",
    "\t2.1 delete rows with empty values  \n",
    "\t2.2 delete rows with NaN  \n",
    "\t2.3 delete rows with only the text \\[deleted\\]  \n",
    "\t2.4 delete rows with only the text \\[removed\\]  \n",
    "  \n",
    "3. Remove markdown marks   \n",
    "\t3.1 remove \\&gt; and \\&gt;/- and \\&amp; and \\#x200B and \\/-; and \\&lt;   \n",
    "\t3.2 remove all *  \n",
    "\t3.3 remove all square brackets  \n",
    "  \n",
    "4. Remove all links using  a regex\n",
    "  \n",
    "\n",
    "\n",
    "\\#x200B; is a 'zero-width space' which is a character that acts like a spacebar, except its invisible. \n",
    "[resource](https://www.reddit.com/r/OutOfTheLoop/comments/9abjhm/what_does_x200b_mean/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022b2dcc",
   "metadata": {},
   "source": [
    "## preprocessing each subreddit\n",
    "  \n",
    "1. only selecting the following columns created_utc, subreddit, id and body.  \n",
    "2. After that following the preprocessing steps as mentioned above  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87ac5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "\n",
    "subreddit = 'worldnews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d12ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr1 = pd.read_csv(f'ds_master/{subreddit}_masterfile.csv', low_memory=False)\n",
    "# sr1 = pd.read_csv(f'ds_master/{subreddit}_masterfile.csv', low_memory=False, lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c69fb",
   "metadata": {},
   "source": [
    "### Calculate length of dataset before pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c92a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr_length = len(sr1)\n",
    "print(sr_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbcf53d",
   "metadata": {},
   "source": [
    "### selecting specific columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410518cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a8deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = sr1\n",
    "\n",
    "# Select the specific columns you want to keep.\n",
    "columns_to_keep = ['created_utc', 'utc_datetime_str', 'subreddit', 'id', 'body']\n",
    "df_new = df_new[columns_to_keep]\n",
    "\n",
    "\n",
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf1105",
   "metadata": {},
   "source": [
    "### Delete rows that do not have an (unique) ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ab06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_id = df_new[df_new['id'].isna()]\n",
    "num_rows_without_id = len(df_without_id)\n",
    "print(f\"Number of rows without an ID: {num_rows_without_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.dropna(subset=['id'])\n",
    "print(len(df_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10095c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8551c",
   "metadata": {},
   "source": [
    "### remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83191ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ids = df_new[df_new.duplicated(subset=['id'], keep=False)]\n",
    "duplicates_df = pd.DataFrame(duplicate_ids)\n",
    "\n",
    "duplicates_df.to_csv(f'ds_test/{subreddit}_duplicates.csv', index=False)\n",
    "print(len(duplicates_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc58d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.drop_duplicates(subset=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f3c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c68e3",
   "metadata": {},
   "source": [
    "### delete rows with empty body text\n",
    "\n",
    "this includes empty rows or rows with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef30600",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_new['body'].notnull()\n",
    "df_new = df_new[mask]\n",
    "print(len(df_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a43102",
   "metadata": {},
   "source": [
    "delete rows where the body text only contains the word '\\[deleted\\]' or '\\[removed\\]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934cf1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_new['body'].str.contains('[removed]', regex=False) == False) & (df_new['body'].str.contains('[deleted]', regex=False) == False) & (df_new['body'].str.strip() != '')\n",
    "df_new = df_new[mask]\n",
    "print(len(df_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512dae6",
   "metadata": {},
   "source": [
    "### delete markdown marks\n",
    "\n",
    "such as \\&gt; and \\&gt;/- and \\&amp; and \\#x200B and \\/-; and \\&lt;   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b760b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving it in a new dataframe \n",
    "df_pro = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro['body'] = df_pro['body'].str.replace('&gt;', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb1c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro['body'] = df_pro['body'].str.replace('&gt;/-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db0900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro['body'] = df_pro['body'].str.replace('&amp;', '&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731ab05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro['body'] = df_pro['body'].str.replace('/-;', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro['body'] = df_pro['body'].str.replace('&lt;', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63464133",
   "metadata": {},
   "source": [
    "### remove other characters \n",
    "\n",
    "such as * and all square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro['body'] = df_pro['body'].str.replace('*', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c929f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro['body'] = df_pro['body'].str.replace('[', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd522d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro['body'] = df_pro['body'].str.replace(']', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b2d1ad",
   "metadata": {},
   "source": [
    "### remove all urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455e4da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2816a85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_pattern = r'\\(?(?:https?:\\/\\/|www\\.)\\S+\\b\\)?'\n",
    "\n",
    "df_pro['body'] = df_pro['body'].str.replace(url_pattern, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ecef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro['body'] = df_pro['body'].str.replace('/)', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7b755",
   "metadata": {},
   "source": [
    "## saving pre-processed data into a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cd79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_pro['body'].notnull()\n",
    "df_pro = df_pro[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_pro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4781afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pro.to_csv(f'ds_preprocessed/{subreddit}_masterfile_preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5131c725",
   "metadata": {},
   "source": [
    "## combine all preprocessed files into one master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f857dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'ds_preprocessed'\n",
    "staticfilename = '_masterfile_preprocessed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fae803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solo testing problamatic files with lineterminator\n",
    "sr6 = pd.read_csv(f'{directory}/environment{staticfilename}.csv', low_memory=False, lineterminator='\\n')\n",
    "print(len(sr6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e214d09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all master files per subreddit\n",
    "sr1 = pd.read_csv(f'{directory}/askreddit{staticfilename}.csv', low_memory=False)\n",
    "sr2 = pd.read_csv(f'{directory}/climate{staticfilename}.csv', low_memory=False)\n",
    "sr3 = pd.read_csv(f'{directory}/climatechange{staticfilename}.csv', low_memory=False, lineterminator='\\n')\n",
    "sr4 = pd.read_csv(f'{directory}/climateskeptics{staticfilename}.csv', low_memory=False)\n",
    "sr5 = pd.read_csv(f'{directory}/collapse{staticfilename}.csv', low_memory=False)\n",
    "sr6 = pd.read_csv(f'{directory}/environment{staticfilename}.csv', low_memory=False, lineterminator='\\n')\n",
    "sr7 = pd.read_csv(f'{directory}/futurology{staticfilename}.csv', low_memory=False)\n",
    "sr8 = pd.read_csv(f'{directory}/news{staticfilename}.csv', low_memory=False)\n",
    "sr9 = pd.read_csv(f'{directory}/politics{staticfilename}.csv', low_memory=False)\n",
    "sr10 = pd.read_csv(f'{directory}/science{staticfilename}.csv', low_memory=False)\n",
    "sr11 = pd.read_csv(f'{directory}/worldnews{staticfilename}.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1221f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da5df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_def.append(sr1)\n",
    "df_def.append(sr2)\n",
    "df_def.append(sr3)\n",
    "df_def.append(sr4)\n",
    "df_def.append(sr5)\n",
    "df_def.append(sr6)\n",
    "df_def.append(sr7)\n",
    "df_def.append(sr8)\n",
    "df_def.append(sr9)\n",
    "df_def.append(sr10)\n",
    "df_def.append(sr11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b37a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(df_def, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78358df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('ds_master/reddit_climatechange_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(combined_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535cab6c",
   "metadata": {},
   "source": [
    "## Saving raw files as one master file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a409cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'ds_master'\n",
    "staticfilename = '_masterfile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250bbcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all master files per subreddit\n",
    "sr1 = pd.read_csv(f'{directory}/askreddit{staticfilename}.csv', low_memory=False)\n",
    "sr2 = pd.read_csv(f'{directory}/climate{staticfilename}.csv', low_memory=False)\n",
    "sr3 = pd.read_csv(f'{directory}/climatechange{staticfilename}.csv', low_memory=False, lineterminator='\\n')\n",
    "sr4 = pd.read_csv(f'{directory}/climateskeptics{staticfilename}.csv', low_memory=False)\n",
    "sr5 = pd.read_csv(f'{directory}/collapse{staticfilename}.csv', low_memory=False)\n",
    "sr6 = pd.read_csv(f'{directory}/environment{staticfilename}.csv', low_memory=False, lineterminator='\\n')\n",
    "sr7 = pd.read_csv(f'{directory}/futurology{staticfilename}.csv', low_memory=False)\n",
    "sr8 = pd.read_csv(f'{directory}/news{staticfilename}.csv', low_memory=False)\n",
    "sr9 = pd.read_csv(f'{directory}/politics{staticfilename}.csv', low_memory=False)\n",
    "sr10 = pd.read_csv(f'{directory}/science{staticfilename}.csv', low_memory=False)\n",
    "sr11 = pd.read_csv(f'{directory}/worldnews{staticfilename}.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ccfec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96a0855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.append(sr1)\n",
    "df_raw.append(sr2)\n",
    "df_raw.append(sr3)\n",
    "df_raw.append(sr4)\n",
    "df_raw.append(sr5)\n",
    "df_raw.append(sr6)\n",
    "df_raw.append(sr7)\n",
    "df_raw.append(sr8)\n",
    "df_raw.append(sr9)\n",
    "df_raw.append(sr10)\n",
    "df_raw.append(sr11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19f867d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_raw_df = pd.concat(df_raw, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e2e941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2658428\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates\n",
    "duplicate_raw_ids = combined_raw_df[combined_raw_df.duplicated(subset=['id'], keep=False)]\n",
    "duplicates_raw_df = pd.DataFrame(duplicate_raw_ids)\n",
    "\n",
    "print(len(duplicates_raw_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b7812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "combined_raw_df.drop_duplicates(subset=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1fc440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2042862\n"
     ]
    }
   ],
   "source": [
    "print(len(combined_raw_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee69c464",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_raw_df.to_csv('ds_master/reddit_climatechange_raw-dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e6c468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_10_rows = combined_raw_df.tail(10)\n",
    "last_10_rows.to_csv('ds_master/reddit_climatechange_raw-dataset-snippet10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c051230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
